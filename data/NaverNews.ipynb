{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장해놓은 naver 주가 데이터에서 날짜 데이터 이용\n",
    "df = pd.read_csv('stock/naver_stock_data.csv') \n",
    "date_list = [i.replace('-', '.') for i in df['Date']] # 형식 변환 (2023-06-01 -> 2023.06.01)\n",
    "\n",
    "# 기사 제목과 날짜를 저장할 최종 데이터프레임\n",
    "news_df = pd.DataFrame(columns=['Title', 'Date']) \n",
    "\n",
    "# \"네이버\" URL 인코딩\n",
    "query = \"네이버\"\n",
    "encQuery = urllib.parse.quote(query)\n",
    "\n",
    "# 날짜마다 관련도 기준 상위 40개 기사 추출 \n",
    "for date in tqdm(date_list): # 날짜마다 기사 추출 반복 (진행률 표시)\n",
    "        title_list = [] # 해당 날짜의 40개의 기사 제목을 저장할 리스트\n",
    "        for start in [1, 11, 21, 31]: # 각 start 마다 10개 기사 추출 (1~10, 11~20 ...)\n",
    "                date1 = date.replace('.', '') # 형식 변환1 (2023.06.01 -> 20230601)\n",
    "\n",
    "                # 네이버 뉴스 검색 URL 생성\n",
    "                url =  \"https://search.naver.com/search.naver?where=news\"\\\n",
    "                        + f\"&query={encQuery}\"\\\n",
    "                        + f\"&ds={date}&de={date}\"\\\n",
    "                        + f\"&nso=so%3Ar%2Cp%3Afrom{date1}to{date1}\"\\\n",
    "                        + f\"&start={start}\" # 날짜당 4개씩 url 생성\n",
    "                \n",
    "                # 웹 페이지의 HTML 콘텐츠를 가져와 BeautifulSoup으로 파싱\n",
    "                web = requests.get(url, headers=headers).content\n",
    "                soup = BeautifulSoup(web, 'html.parser') # BeautifulSoup 객체 soup\n",
    "                \n",
    "                # 뉴스 제목 추출 후 title_list에 추가\n",
    "                ## 'a' 태그 중 클래스가 'news_tit'인 모든 요소를 찾아 텍스트 추출 -> titles 리스트 (url 마다 10개씩)\n",
    "                titles = [title.text.strip()  for title in soup.find_all('a', attrs={'class':'news_tit'})]\n",
    "                ## url 마다 10개씩의 제목들을 누적 추가하여 날짜마다 총 40개씩 저장\n",
    "                title_list.extend(titles)\n",
    "        \n",
    "        # 날짜마다 모은 40개의 기사들을 저장할 임시 데이터프레임\n",
    "        temp_df = pd.DataFrame({\n",
    "                'Title': title_list, \n",
    "                'Date': [date] * len(title_list) # 모은 기사 개수만큼 날짜 리스트 사이즈 맞추기\n",
    "        })\n",
    "\n",
    "        # 최종 데이터프레임에 임시 데이터프레임을 넣어서 날짜마다 계속 누적\n",
    "        news_df = pd.concat([news_df, temp_df], ignore_index=True)\n",
    "\n",
    "print(\"----끝----\") # 총 9640 (= 241(날짜) * 40(기사))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title\n",
       "40    241\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 날짜별로 기사가 40개씩 제대로 모아졌나 확인\n",
    "groupby_news_df = news_df.groupby(['Date'])[['Title']].count()\n",
    "groupby_news_df['Title'].value_counts() # 성공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>앳홈, 미닉스 미니 건조기 네이버 쇼핑에서 론칭</td>\n",
       "      <td>2023.06.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>앳홈, 미닉스 미니 건조기 네이버 쇼핑에서 론칭</td>\n",
       "      <td>2023.06.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>“7천원 냈는데, 쓰지도 못하고 환불 받아라?” 네이버 왜 이래?</td>\n",
       "      <td>2023.06.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>“7천원 냈는데, 쓰지도 못하고 환불 받아라?” 네이버 왜 이래?</td>\n",
       "      <td>2023.06.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>고려은단, 네이버 메가세일&amp;쇼핑라이브 진행</td>\n",
       "      <td>2023.06.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9606</th>\n",
       "      <td>라인 장수게임 잇단 종료…네이버와 거리두나</td>\n",
       "      <td>2024.05.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9607</th>\n",
       "      <td>'COO도 지원사격' 네이버 치지직…\"팝업스토어 성료, 굿즈 품절 대란도\"</td>\n",
       "      <td>2024.05.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9613</th>\n",
       "      <td>네이버-카카오, 검색·쇼핑 등 전방위 위기 고조</td>\n",
       "      <td>2024.05.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9614</th>\n",
       "      <td>라인 장수게임 잇단 종료…네이버와 거리두나</td>\n",
       "      <td>2024.05.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9615</th>\n",
       "      <td>'COO도 지원사격' 네이버 치지직…\"팝업스토어 성료, 굿즈 품절 대란도\"</td>\n",
       "      <td>2024.05.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>554 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title        Date\n",
       "49                   앳홈, 미닉스 미니 건조기 네이버 쇼핑에서 론칭  2023.06.02\n",
       "50                   앳홈, 미닉스 미니 건조기 네이버 쇼핑에서 론칭  2023.06.02\n",
       "169        “7천원 냈는데, 쓰지도 못하고 환불 받아라?” 네이버 왜 이래?  2023.06.08\n",
       "171        “7천원 냈는데, 쓰지도 못하고 환불 받아라?” 네이버 왜 이래?  2023.06.08\n",
       "217                     고려은단, 네이버 메가세일&쇼핑라이브 진행  2023.06.09\n",
       "...                                         ...         ...\n",
       "9606                    라인 장수게임 잇단 종료…네이버와 거리두나  2024.05.27\n",
       "9607  'COO도 지원사격' 네이버 치지직…\"팝업스토어 성료, 굿즈 품절 대란도\"  2024.05.27\n",
       "9613                 네이버-카카오, 검색·쇼핑 등 전방위 위기 고조  2024.05.27\n",
       "9614                    라인 장수게임 잇단 종료…네이버와 거리두나  2024.05.27\n",
       "9615  'COO도 지원사격' 네이버 치지직…\"팝업스토어 성료, 굿즈 품절 대란도\"  2024.05.27\n",
       "\n",
       "[554 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기사 제목이 중복되는 행 보기\n",
    "news_df[news_df.duplicated(subset=['Title'], keep=False)]\n",
    "\n",
    "# 확인해보니 같은 언론사 -> 무의미하다고 생각하여 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기사 제목 기준 중복되는 행 삭제\n",
    "news_df = news_df.drop_duplicates(subset=['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.to_csv('naver_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
